%%==================================================
%% chapter02.tex for BIT Master Thesis
%% modified by yang yating
%% version: 0.1
%% last update: Dec 25th, 2016
%%==================================================
\chapter{基于预训练辅助模型的Token表征学习}
本章主要对本文提出的基于预训练辅助模型的Token表征学习方法进行详细介绍，首先介绍其基本思想，接着阐述其方法设计，以及具体的实现过程，最后介绍实验验证过程和结果。
\section{研究动机}

本文针对现有存在的问题，

基于Token的代码表征通常利用词法分析器将代码中的词汇单元（Token）划分出来。这些词汇单元通常包含关键字、数字、标识符等。将代码表示为词汇单元序列之后，利用深度学习技术对其进行建模，学习代码序列中所包含的有效信息，如功能语义信息、语法结构信息等，最后生成具有丰富代码信息的表征向量，应用于后续的代码克隆检测任务中。现有方法大多都对token进行了规范化，比如将变量名用统一的标识符来代替，这样存在的问题是会丢失部分词法信息，但是如果不进行规范化，会存在集外词（Out-of-vocabulary，简称OOV）的问题，即出现了在词汇表中不存在的token。集外词OOV问题严重限制了代码表示的有效性。

针对上述问题，本文采用预训练增强的辅助模型得到词汇表，从而提高代码克隆检测的准确率。
\section{方法设计}

本节将主要介绍基于预训练辅助模型的Token表征学习方法设计与实现，首先介绍该方法的整体框架，并分别从预训练辅助模型、Token表征学习的具体设计及实现。

\subsection{框架概述}
基于预训练辅助模型的Token表征学习：

\subsection{预训练辅助模型}
Word2vec模型 多次迭代维护词汇表，从而减少OOV问题

在模型训练之前，通过选取合适的模型从代码语料库中学习基本单元的语法语义信息，以及这些单元之间的联系，最终给出一份单词-向量形式的词汇表，从而减少出现集外词问题的概率。具体的，第一次迭代选择相邻的两个token组合为一个单元，查找出最频繁的token组合确定为一个组合单元，并将组合单元更新到词汇表中，然后二次迭代，每次迭代在原来的基本单元上再组合一个新的邻近token作为新的判断单元，每次迭代都会更新词汇表。在得到词汇表之后，根据词汇表获取每个单元的向量表示。
\subsection{Token表征学习}
采用BiLST模型

将token序列对应的向量输入到Bi LSTM网络中，经过Bi LSTM学习哪些信息应该被记住哪些信息应该被遗忘，最终得到每个基本单元包含语义信息和上下文信息的向量表示。Bi LSTM由一个正向的LSTM和一个反向的LSTM组成，主要思想是通过把序列向前、向后分别输入给两个独立的递归网络，这两个子网络连接到一个输出层，在每个词的输出部分把两个子网络的输出信息进行整合，这样网络就同时拥有了序列中每个词的过去时刻信息和未来时刻信息。Bi LSTM可以捕获到序列前后的关系依赖，将代码片段的Token序列转换为可相互比较的向量。
\section{实验验证}
为了验证基于预训练辅助模型的Token表征方法的有效性，

\subsection{实验设计}
（1）实验环境

（2）实验数据集
POJ104数据集

（3）评估指标
分类问题 采用召回率(Recall)、精确度(Precision)和准确率（Accuracy）三个指标评价实验结果

\subsection{预训练辅助模型实验结果}
消融对比实验：体现改进的辅助模型的有效性
基于Token的Bi LSTM
基于Token的+预训练辅助模型的Bi LSTM


\begin{table}
  \centering
  \caption{预训练辅助模型实验结果} \label{tab:category}
  \begin{tabular*}{0.9\textwidth}{@{\extracolsep{\fill}}cccc}
  \toprule
    对比			&P		&R		&F1 \\
  \midrule
    基于Token的Bi LSTM			&0.xx	&0.xx		&0.xx \\
    基于Token的+预训练辅助模型的Bi LSTM			&0.xx		&0.xx		&0.xx \\
  \bottomrule
  \end{tabular*}
\end{table}

\section{本章小结}
本章



